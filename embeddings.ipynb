{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (6.29.5)\n",
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting plotly\n",
      "  Using cached plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: appnope in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (1.8.8)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Collecting scipy>=1.3.1 (from umap-learn)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn>=0.22 (from umap-learn)\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Using cached numba-0.60.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from umap-learn) (4.66.5)\n",
      "Collecting tenacity>=6.2.0 (from plotly)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: decorator in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.2->umap-learn)\n",
      "  Using cached llvmlite-0.43.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting joblib>=0.11 (from pynndescent>=0.5->umap-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.22->umap-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Using cached umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Using cached plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "Using cached numba-0.60.0-cp312-cp312-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached llvmlite-0.43.0-cp312-cp312-macosx_11_0_arm64.whl (28.8 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, tenacity, scipy, llvmlite, joblib, scikit-learn, plotly, numba, pynndescent, umap-learn\n",
      "Successfully installed joblib-1.4.2 llvmlite-0.43.0 numba-0.60.0 plotly-5.24.1 pynndescent-0.5.13 scikit-learn-1.5.2 scipy-1.14.1 tenacity-9.0.0 threadpoolctl-3.5.0 umap-learn-0.5.7\n"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel umap-learn plotly numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expect a disk size of 344.993100 MB for the embeddings.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/embeddings/embedding_batch_2024-11-26-17-29-02.jsonl'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Producing a batch request dataset and saving to disk.\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "EMBEDDING_DIM = 512\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
    "MAX_LINES = 50_000\n",
    "SKIP = True\n",
    "\n",
    "def write_embedding_batch_dataset(story_filepath, model):\n",
    "    # Create embeddings path if non-existent\n",
    "    out_filename = f\"data/embeddings/embedding_batch_{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.jsonl\"  \n",
    "    if not os.path.exists(\"data/embeddings\"):\n",
    "        os.makedirs(\"data/embeddings\")\n",
    "    with open(story_filepath, \"r\") as in_f, open(out_filename, \"w\") as out_f:\n",
    "        \n",
    "        lines = []\n",
    "        for k, line in enumerate(in_f):\n",
    "            entry = json.loads(line)\n",
    "            lines.append(json.dumps(\n",
    "                {\n",
    "                    \"custom_id\": entry[\"generation_id\"],\n",
    "                    \"method\": \"POST\",\n",
    "                    \"url\": \"/v1/embeddings\",\n",
    "                    \"body\": {\"model\": model, \"input\": entry[\"story\"], \"dimensions\": EMBEDDING_DIM}\n",
    "                }\n",
    "            ))\n",
    "            if len(lines) + 1 >= MAX_LINES:\n",
    "                break\n",
    "            if SKIP and (k % 5 != 0):\n",
    "                continue\n",
    "            \n",
    "\n",
    "        print(f\"Expect a disk size of {len(lines) * (EMBEDDING_DIM / 3072) * 0.0414:0f} MB for the embeddings.\")\n",
    "\n",
    "        out_f.write(\"\\n\".join(lines))\n",
    "\n",
    "        return out_filename\n",
    "\n",
    "stories_file = \"data/batches_2024-11-12-17-00-38/processed.jsonl\"\n",
    "write_embedding_batch_dataset(stories_file, EMBEDDING_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock embeddings file created at: data/embeddings/mock_embeddings_file.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, generate a mock response:\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Input and output file paths\n",
    "stories_file = \"data/batches_2024-11-12-17-00-38/processed.jsonl\"\n",
    "embeddings_file = \"data/embeddings/mock_embeddings_file.jsonl\"  # Path to generate the embeddings_file\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 100\n",
    "MAX_LINES = 5_000\n",
    "\n",
    "# Read stories_data\n",
    "stories_data = []\n",
    "with open(stories_file, 'r') as f:\n",
    "    for k, line in enumerate(f):\n",
    "        stories_data.append(json.loads(line))\n",
    "        if len(stories_data) + 1 >= MAX_LINES:\n",
    "                break\n",
    "        if SKIP and (k % 5 != 0):\n",
    "            continue\n",
    "\n",
    "# Generate embeddings and write to embeddings_file\n",
    "with open(embeddings_file, 'w') as f:\n",
    "    for story in stories_data:\n",
    "        generation_id = story['generation_id']\n",
    "        embedding = np.random.normal(size=embedding_dim).tolist()\n",
    "        \n",
    "        # Create the embedding entry\n",
    "        embedding_entry = {\n",
    "            \"custom_id\": generation_id,\n",
    "            \"response\": {\n",
    "                \"body\": {\n",
    "                    \"data\": [\n",
    "                        {\"embedding\": embedding}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Write to file as a JSON object\n",
    "        f.write(json.dumps(embedding_entry) + '\\n')\n",
    "\n",
    "print(f\"Mock embeddings file created at: {embeddings_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Retrieving the batch through the OpenAI Web UI and saving to disk (To be implemented in code if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49999/49999 [00:06<00:00, 7602.33it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. Analyzing the embeddings\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def story_start(input_string):\n",
    "    for delimiter in [\",\", \".\"]:\n",
    "        if delimiter in input_string:\n",
    "            first_part = input_string.split(delimiter, 1)[0]\n",
    "            break\n",
    "    words = first_part.split()\n",
    "    if len(words) <= 10:\n",
    "        return ' '.join(word.capitalize() for word in words)\n",
    "    else:\n",
    "        return ' '.join(word.capitalize() for word in words[:3])\n",
    "\n",
    "MAX_LINES = 50_000\n",
    "SKIP = False\n",
    "embeddings_file = \"data/embeddings/batch_6745f7c140588190b1dcb1a1fd9ae532_output.jsonl\"\n",
    "stories_file = \"data/batches_2024-11-12-17-00-38/processed.jsonl\"\n",
    "\n",
    "embeddings_data = []\n",
    "with open(embeddings_file, 'r') as f:\n",
    "    for line in f:\n",
    "        embeddings_data.append(json.loads(line))\n",
    "\n",
    "stories_data = []\n",
    "with open(stories_file, 'r') as f:\n",
    "    for k, line in enumerate(f):\n",
    "        stories_data.append(json.loads(line))\n",
    "        if len(stories_data) + 1 >= MAX_LINES:\n",
    "                break\n",
    "        if SKIP and (k % 5 != 0):\n",
    "            continue\n",
    "\n",
    "story_dict = {story['generation_id']: k for k, story in enumerate(stories_data)}\n",
    "matched_data = []\n",
    "for embedding_entry in tqdm(embeddings_data):\n",
    "    story_index = story_dict[embedding_entry['custom_id']]\n",
    "    embedding = embedding_entry['response']['body']['data'][0]['embedding']\n",
    "    story_info = stories_data[story_index]\n",
    "    wrapped_story = '\\n'.join(textwrap.wrap(story_info['story'], width=50))\n",
    "    matched_data.append({\n",
    "        'embedding': embedding,\n",
    "        'story': wrapped_story,\n",
    "        'theme': story_info['theme'],\n",
    "        'topic': story_info['topic'],\n",
    "        'persona': story_info['persona'],\n",
    "        'grammar': story_info['grammar'],\n",
    "        'id': story_info['generation_id'],\n",
    "        'feature': story_info['feature'],\n",
    "        'style': story_info['style'],\n",
    "        'model': story_info['model'],\n",
    "        'title': story_start(story_info['story'])\n",
    "    })\n",
    "\n",
    "embeddings = np.array([item['embedding'] for item in matched_data])\n",
    "umap_reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "embedding_2d = umap_reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt to the format required by the web app\n",
    "MAX_LINES_WEB = 5_000\n",
    "\n",
    "final_data = []\n",
    "for i, item in enumerate(matched_data):\n",
    "    final_data.append({\n",
    "        \"id\": item['id'],\n",
    "        \"embedding1\": float(embedding_2d[i][0]),\n",
    "        \"embedding2\": float(embedding_2d[i][1]),\n",
    "        \"title\": item['title'].capitalize(),\n",
    "        \"style\": item['style'].capitalize(),\n",
    "        \"topic\": item['topic'].capitalize(),\n",
    "        \"theme\": item['theme'].capitalize(),\n",
    "        \"persona\": item['persona'].capitalize(),\n",
    "        \"grammar\": item['grammar'].capitalize(),\n",
    "        \"feature\": item['feature'].capitalize(),\n",
    "        \"model\": item['model'],\n",
    "        \"story\": item['story'].replace('\\n', ' ').replace('  ', '\\n\\n')\n",
    "    })\n",
    "    if i + 1 >= MAX_LINES_WEB:\n",
    "        break\n",
    "\n",
    "output_file = 'stories.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(final_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'style': ['Lighthearted', 'Tragic', 'Modern', 'Mystical', 'Mythological', 'Adventurous', 'Melancholic', 'Humorous', 'Romantic', 'Action-packed', 'Heartwarming', 'Epic', 'Lyric', 'Minimalist', 'Whimsical', 'Classic', 'Noir', 'Fable-like', 'Suspenseful', 'Surreal', 'Playful', 'Fairy tale-like', 'Philosophical'], 'topic': ['Superheroes', 'Space exploration', 'Snowy adventures', 'Holidays', 'Gardens', 'Dream worlds', 'Sibling rivalry', 'Alien encounters', 'A deadline or time limit', 'Mysterious maps', 'Fantasy worlds', 'Robots and technology', 'Unusual vehicles', 'Lost civilizations', 'Virtual worlds', 'Magical objects', 'Haunted places', 'Miniature worlds', 'Bygone eras', 'Hidden treasures', 'Mystical creatures', 'Subterranean worlds', 'Invisibility', 'Pirates', 'Dinosaurs', 'Underwater adventures', 'Enchanted forests', 'Cultural traditions', 'Talking animals', 'Magical lands', 'The sky', 'School life', 'Living objects', 'Giant creatures', 'Shape-shifting', 'Undercover missions', 'Outer space', 'Sports', 'Riddles', 'Island adventures', 'Royal kingdoms', 'The arts', 'Fairy tales', 'Seasonal changes', 'Time travel', 'Secret societies', 'Lost cities', 'Treasure hunts'], 'theme': ['Dreams', 'Amnesia', 'Magic', 'Generosity', 'Morality', 'Hardship', 'Overcoming', 'Hope', 'Power', 'Optimism', 'Conflict', 'Kindness', 'Conscience', 'Friendship', 'Courage', 'Discovery', 'Belonging', 'Betrayal', 'Strategy', 'Perseverance', 'Love', 'Humor', 'Deception', 'Intelligence', 'Family', 'Adventure', 'Consciousness', 'Trust', 'Cooperation', 'Resilience', 'Honesty', 'The five senses', 'Revenge', 'Creativity', 'Planning', 'Wonder', 'Challenge', 'Curiosity', 'Imagination', 'Logic', 'Self-acceptance', 'Helping others', 'Loss', 'Surprises', 'Happiness', 'Tradition', 'Long-term thinking', 'Innovation', 'Travel', 'Celebration', 'Scheming', 'Romance', 'Teamwork', 'Failure', 'Independence', 'Contradiction', 'Transformation', 'Growth', 'Problem-solving', 'Agency', 'Coming of age', 'Responsibility', 'Resourcefulness'], 'persona': ['', 'An innocent author', 'An explorer archetype', 'The oppressed', 'A hurt, ill-intentioned person', 'A rebellious author', 'Someone who wants to prove a point', 'An academic', 'A child', 'A pedant', 'The everyman', 'Someone who loves order and structure', 'A wise, old person who wants to teach the young', 'Someone evil', 'A hopeless romantic', 'A powerful leader', 'A father', 'A cruel person', 'A moralistic teacher', 'A poet', 'Someone curious', 'A jester archetype', 'A philosopher', 'A mother'], 'grammar': ['', 'Future tense', 'Perfect aspect', 'Subordinate clauses', 'Appositive phrases', 'Conditional mood', 'Indicative mood', 'Ellipsis', 'Past tense', 'Superlative forms', 'Quantifiers', 'Yes-no questions', 'Indirect speech', 'Prepositional phrases', 'Relative clauses', 'Wh-questions', 'Progressive aspect', 'Cataphora', 'Imperative mood', 'Anaphora', 'Comparative forms', 'Inverted sentences', 'Present tense', 'Adjective order', 'Participle phrases', 'Passive voice', 'Exclamative sentences', 'Determiners', 'Non-finite clauses', 'Discourse markers', 'Parallel structure', 'Gerunds'], 'feature': ['A flashback', \"Checkhov's gun\", 'A red herring', 'A non-linear timeline', 'Inner monologue', 'Symbolism', 'A cliffhanger', 'Juxtaposition', 'Multiple perspectives', 'The fourth wall', 'Climactic structure', 'Circular narrative structure', 'A story told through letters', 'A reverse timeline', 'A moral lesson', 'Irony', 'A nested structure', 'A twist ending', 'A story within a story', 'Dialogue', 'Foreshadowing', 'An anti-hero', 'In medias res', 'A macguffin', 'Absence indicating a presence', 'An unrealiable narrater']}\n"
     ]
    }
   ],
   "source": [
    "# Getting unique values for each feature\n",
    "unique_features = {key: list(set([item[key] for item in final_data])) for key in ['topic', 'style', 'theme', 'persona', 'grammar', 'feature']}\n",
    "print(unique_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/4999 [00:06<35:41,  2.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(embeddings))):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(embeddings)):\n\u001b[0;32m---> 16\u001b[0m         similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m         distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m similarity\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m distance \u001b[38;5;241m>\u001b[39m max_distance:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1685\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1683\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1685\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1687\u001b[0m K \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39mdense_output)\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:1933\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     sparse_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1931\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m-> 1933\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1942\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_writeable:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;66;03m# By default, array.copy() creates a C-ordered copy. We set order=K to\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;66;03m# preserve the order of the array.\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m     copy_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array) \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1107\u001b[0m     array_data \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m array\n\u001b[1;32m   1108\u001b[0m     flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(array_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(flags, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriteable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;66;03m# This situation can only happen when copy=False, the array is read-only and\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m         \u001b[38;5;66;03m# a writeable output is requested. This is an ambiguous setting so we chose\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;66;03m# to always (except for one specific setting, see below) make a copy to\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;66;03m# ensure that the output is writeable, even if avoidable, to not overwrite\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;66;03m# the user's data by surprise.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/sparse/_base.py:1335\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A namespace class to separate sparray from spmatrix\"\"\"\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \n\u001b[1;32m   1338\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find closest Stories (Marked for deletion, too slow)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Convert the list of embeddings into a numpy array\n",
    "embeddings = np.array([entry['embedding'] for entry in matched_data])\n",
    "\n",
    "max_distance = -1\n",
    "story_pair = (None, None)\n",
    "\n",
    "# Iterate over all pairs of embeddings to compute the cosine distance\n",
    "for i in tqdm(range(len(embeddings))):\n",
    "    for j in range(i + 1, len(embeddings)):\n",
    "        similarity = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "        distance = 1 - similarity\n",
    "        if distance > max_distance:\n",
    "            max_distance = distance\n",
    "            story_pair = (i, j)\n",
    "\n",
    "if story_pair[0] is not None and story_pair[1] is not None:\n",
    "    story1 = matched_data[story_pair[0]]['story']\n",
    "    story2 = matched_data[story_pair[1]]['story']\n",
    "    print(\"Story 1 with maximal cosine distance:\")\n",
    "    print(story1)\n",
    "    print(\"\\nStory 2 with maximal cosine distance:\")\n",
    "    print(story2)\n",
    "else:\n",
    "    print(\"No stories to compare.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualization with Plotly\n",
    "\n",
    "df = pd.DataFrame(embedding_2d, columns=['x', 'y'])\n",
    "df['story'] = [item['story'].replace(\"\\n\", \"<br>\").strip() for item in matched_data]\n",
    "df['theme'] = [item['theme'] for item in matched_data]\n",
    "df['topic'] = [item['topic'] for item in matched_data]\n",
    "\n",
    "hover_template = \"<b>Story:</b><br>%{customdata[0]}<br><extra></extra>\"\n",
    "\n",
    "fig = px.scatter(df, x='x', y='y', symbol='theme', color='topic', \n",
    "                 hover_data={'story': True, 'theme': False, 'x': False, 'y': False},\n",
    "                 custom_data=['story'],\n",
    "                 title=\"UMAP of Story Embeddings\")\n",
    "\n",
    "fig.update_traces(hovertemplate=hover_template)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={'x': 0.5},\n",
    "    xaxis_title=None,\n",
    "    yaxis_title=None,\n",
    "    margin=dict(l=0, r=0, t=50, b=0),\n",
    "    legend_title_text='',\n",
    "    hoverlabel=dict(font_size=11),\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"data/embeddings/web\"):\n",
    "    os.makedirs(\"data/embeddings/web\")\n",
    "fig.write_html(\"data/embeddings/web/index.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbformat\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat)\n",
      "  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/pc/Library/Python/3.12/lib/python/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/pc/Library/Python/3.12/lib/python/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/pc/Library/Python/3.12/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.3)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: fastjsonschema, nbformat\n",
      "Successfully installed fastjsonschema-2.20.0 nbformat-5.10.4\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
